version: "3.8"

services:
  llamapress:
    # image: kody06/llamapress-simple:0.3.1        # <â€” pre-built tag
    build: ../LlamaPress-Simple
    env_file: .env                           # read secrets from this file
    environment:
      - RAILS_ENV=development
      - BOOTSNAP_CACHE_DIR=/rails/tmp/cache/bootsnap
    volumes:
      - rails_storage:/rails/storage         # ActiveStorage local files
      - ./rails/app:/rails/app
      - ./rails/config/routes.rb:/rails/config/routes.rb
      - ./rails/db:/rails/db
      - ./rails/spec:/rails/spec:delegated
      - ./rails/config/environments/development.rb:/rails/config/environments/development.rb
      - ./rails/config/database.yml:/rails/config/database.yml
      - ./rails/storage:/rails/storage       # ActiveStorage local files (persisted on host)
      - ../LlamaPress-Simple/vendor/llama_bot_rails:/rails/vendor/llama_bot_rails  # Dev: hot reload gem changes
    command: bash -c "rm -f tmp/pids/server.pid && bundle exec rails db:prepare && bundle exec rails s -b 0.0.0.0"
    # command: tail -f /dev/null
    # docker compose exec -it llamapress bundle exec rails s -b 0.0.0.0
    ports:
      - "3000:3000"                            # http://server_ip/
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - llama-network

  llamabot:
    image: kody06/llamabot:0.3.3u
    # build: ../LlamaBot
    env_file:
      - .env
    command: bash -c "python init_pg_checkpointer.py && uvicorn main:app --host 0.0.0.0 --port 8000"
    # command: bash -c "python init_pg_checkpointer.py && tail -f /dev/null"
    # docker compose exec -it llamabot uvicorn main:app --host 0.0.0.0 --port 8000
    # docker compose exec -it llamabot langgraph dev --host 0.0.0.0
    volumes:
      - auth_json:/app/auth.json
      - ../LlamaBot/app:/app/app  # Dev: full mount for hot reload
      - ./rails:/app/app/rails  # Override: Leonardo's Rails code
      - ./langgraph/langgraph.json:/app/app/langgraph.json  # Override: merged config
      - ./langgraph/agents:/app/app/user_agents  # Add: custom agents
      - /var/run/docker.sock:/var/run/docker.sock
      - ./:/app/leonardo  # Full Leonardo repo for git access
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
    networks:
      - llama-network
  
  db:
    image: postgres:16
    environment:
      POSTGRES_DB:      llamapress_development
      POSTGRES_USER:    postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - llama-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d llamapress_development"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    volumes: [redis_data:/data]
    restart: unless-stopped
    networks:
      - llama-network

  code:
    image: kody06/llamabot-vscode:latest
    container_name: code
    user: root
    environment:
      - TZ=America/Denver
      - PASSWORD=password
    volumes:
      - code_config:/config
      - ./:/config/workspace
    ports:
      - "8443:8443"
    restart: unless-stopped  

  # pgweb:
  #   image: sosedoff/pgweb
  #   ports:
  #     - "8082:8081"
  #   environment:
  #     DATABASE_URL: postgres://postgres:password@db:5432/llamapress_development?sslmode=disable
  #     AUTH_USER: admin
  #     AUTH_PASS: changeme
  #   depends_on:
  #     - db
  #   networks:
  #     - llama-network
      
volumes:
  redis_data:
  postgres_data:
  rails_storage:
  auth_json:
  code_config:

# Declare the external network
networks:
  llama-network:
    name: llama-network